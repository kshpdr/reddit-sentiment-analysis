{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1718 entries, 0 to 1717\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   name             1691 non-null   object \n",
      " 1   title            1718 non-null   object \n",
      " 2   selftext         1270 non-null   object \n",
      " 3   author           1718 non-null   object \n",
      " 4   created_utc      1718 non-null   float64\n",
      " 5   score            1718 non-null   int64  \n",
      " 6   num_comments     1718 non-null   int64  \n",
      " 7   subreddit        1718 non-null   object \n",
      " 8   link_flair_text  1717 non-null   object \n",
      " 9   url              1613 non-null   object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 134.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# specify here path to your data\n",
    "data = pd.read_csv('../data/reddit_posts_3_years.csv')\n",
    "\n",
    "data.head()\n",
    "data.shape\n",
    "data.columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Question' 'Sports' 'Discussion' 'Rant' 'Social/Club' 'Survey/Study/Poll'\n",
      " 'Meme/Shitpost' 'Announcement' 'Photo' 'Other' 'YOUR MOD SPEAKS' 'News'\n",
      " nan 'Job Listing' 'MEGATHREAD' 'Meta' '(Misreported) News' 'MegaThread'\n",
      " 'Social' 'Survey' 'Meme/shitpost']\n"
     ]
    }
   ],
   "source": [
    "# let's see what possible reddit tags do we have for a post\n",
    "unique_flair_texts = data['link_flair_text'].unique()\n",
    "print(unique_flair_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in non-empty 'selftext' columns: 71.52992125984252\n"
     ]
    }
   ],
   "source": [
    "# and how many words on average do we have in a posts\n",
    "non_empty_selftext = data['selftext'].dropna()\n",
    "average_word_count = non_empty_selftext.apply(lambda x: len(x.split())).mean()\n",
    "print(f\"Average number of words in non-empty 'selftext' columns: {average_word_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of characters in non-empty 'selftext' columns: 428.88188976377955\n"
     ]
    }
   ],
   "source": [
    "# lets inspect average number of chars in post to calculate later the cost for using 4o-mini model\n",
    "average_char_count = non_empty_selftext.apply(len).mean()\n",
    "print(f\"Average number of characters in non-empty 'selftext' columns: {average_char_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in 'selftext' column: 544680\n"
     ]
    }
   ],
   "source": [
    "# total chars across all posts\n",
    "total_char_count = non_empty_selftext.apply(len).sum()\n",
    "print(f\"Total number of characters in 'selftext' column: {total_char_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3                  https://i.redd.it/epw2y828kvzd1.jpeg\n",
      "9                  https://i.redd.it/vqesp9lvpnzd1.jpeg\n",
      "12    https://www.reddit.com/r/gatech/comments/1glh4...\n",
      "26                  https://i.redd.it/12zirh5at4zd1.png\n",
      "31                 https://i.redd.it/a6yq8b5nl3zd1.jpeg\n",
      "32               https://www.reddit.com/gallery/1gk7yds\n",
      "36                 https://i.redd.it/58hqahveiwyd1.jpeg\n",
      "37                  https://i.redd.it/pxvn6lcbmzyd1.png\n",
      "42                  https://i.redd.it/uld58v2k8ztd1.png\n",
      "49     https://youtu.be/0-2EXrw09Uw?si=mTXWlDeT46nMk6N_\n",
      "Name: url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# let's inspect posts that don't contain any text at all\n",
    "empty_selftext_posts = data[data['selftext'].isna()]\n",
    "top_10_empty_selftext_posts = empty_selftext_posts[\"url\"].head(10)\n",
    "print(top_10_empty_selftext_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in combined text: 659033\n"
     ]
    }
   ],
   "source": [
    "# let's see how many input chars we'll have for a combined text (title | text | reddit tag)\n",
    "non_empty_selftext_df = data[data['selftext'].notna()]\n",
    "\n",
    "total_combined_text_char_count = non_empty_selftext_df.apply(\n",
    "    lambda row: len(f\"Title: {row['title']} | Selftext: {row['selftext']} | Flair: {row['link_flair_text']}\"), axis=1\n",
    ").sum()\n",
    "\n",
    "print(f\"Total number of characters in combined text: {total_combined_text_char_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your .env file and don't forget to put your OpenAI API key there\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the model you want to be using \n",
    "MODEL=\"gpt-4o-mini\"\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as an env var>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_question = non_empty_selftext_df['combined_text'].iloc[2]\n",
    "completion = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment analysis classifier for a subreddit of Georgia Tech. Most of the most have sentiment so you rarely pick a neutral option, mostly it's either positive or negative. Sometimes, it's neutral mostly when it's a question. Answer only with a single digit: 1 for positive, -1 for negative, 0 for neutral\"},\n",
    "    {\"role\": \"user\", \"content\": neutral_question}  \n",
    "  ]\n",
    ")\n",
    "print(neutral_question)\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_post = non_empty_selftext_df['combined_text'].iloc[3]\n",
    "completion = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment analysis classifier for a subreddit of Georgia Tech. Most of the most have sentiment so you rarely pick a neutral option, mostly it's either positive or negative. Sometimes, it's neutral mostly when it's a question. Answer only with a single digit: 1 for positive, -1 for negative, 0 for neutral\"}, \n",
    "    {\"role\": \"user\", \"content\": positive_post}  \n",
    "  ]\n",
    ")\n",
    "print(positive_post)\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/c4l8s0b1199bp9tl5hlxr75w0000gn/T/ipykernel_88050/966132215.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_empty_selftext_df['4o-mini-sentiment'] = non_empty_selftext_df['combined_text'].apply(get_sentiment)\n"
     ]
    }
   ],
   "source": [
    "# let's create a function to process every row in DF and apply it for the whole dataset\n",
    "def get_sentiment(text):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sentiment analysis classifier for a subreddit of Georgia Tech. Most of the most have sentiment so you rarely pick a neutral option, mostly it's either positive or negative. Sometimes, it's neutral mostly when it's a question. Answer only with a single digit: 1 for positive, -1 for negative, 0 for neutral\"}, # <-- This is the system message that provides context to the model\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    )\n",
    "    return int(completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "non_empty_selftext_df['4o-mini-sentiment'] = non_empty_selftext_df['combined_text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4o-mini-sentiment\n",
      " 0    952\n",
      " 1    187\n",
      "-1    131\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# it took 12 minutes and around $0.04 for all requests, let's see sentiment stats\n",
    "sentiment_counts = non_empty_selftext_df['4o-mini-sentiment'].value_counts()\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How do so many people graduate one year early from Georgia Tech?  | Selftext: people from my class are graduating one year early, i thought  | Flair: Discussion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/c4l8s0b1199bp9tl5hlxr75w0000gn/T/ipykernel_88050/2989016832.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_empty_selftext_df['combined_text_middle'] = non_empty_selftext_df.apply(\n"
     ]
    }
   ],
   "source": [
    "# let's try to minimize cost now by including only the middle part of the text \n",
    "def extract_middle_third(text):\n",
    "    length = len(text)\n",
    "    start = length // 3\n",
    "    end = 2 * length // 3\n",
    "    return text[start:end]\n",
    "\n",
    "non_empty_selftext_df['combined_text_middle'] = non_empty_selftext_df.apply(\n",
    "    lambda row: f\"Title: {row['title']} | Selftext: {extract_middle_third(row['selftext'])} | Flair: {row['link_flair_text']}\", axis=1\n",
    ")\n",
    "\n",
    "print(non_empty_selftext_df['combined_text_middle'].iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 0\n"
     ]
    }
   ],
   "source": [
    "middle_neutral_question = non_empty_selftext_df['combined_text_middle'].iloc[2]\n",
    "completion = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment analysis classifier for a subreddit of Georgia Tech. Most of the most have sentiment so you rarely pick a neutral option, mostly it's either positive or negative. Sometimes, it's neutral mostly when it's a question. Answer only with a single digit: 1 for positive, -1 for negative, 0 for neutral\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": middle_neutral_question}  # <-- This is the user message for which the model will generate a response\n",
    "  ]\n",
    ")\n",
    "print(middle_neutral_question)\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: -1\n"
     ]
    }
   ],
   "source": [
    "negative_post = non_empty_selftext_df['combined_text_middle'].iloc[6]\n",
    "completion = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment analysis classifier for a subreddit of Georgia Tech. Most of the most have sentiment so you rarely pick a neutral option, mostly it's either positive or negative. Sometimes, it's neutral mostly when it's a question. Answer only with a single digit: 1 for positive, -1 for negative, 0 for neutral\"}, # <-- This is the system message that provides context to the model\n",
    "    {\"role\": \"user\", \"content\": negative_post}  # <-- This is the user message for which the model will generate a response\n",
    "  ]\n",
    ")\n",
    "print(negative_post)\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 0\n"
     ]
    }
   ],
   "source": [
    "positive_post = non_empty_selftext_df['combined_text_middle'].iloc[11]\n",
    "completion = client.chat.completions.create(\n",
    "  model=MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a sentiment analysis classifier for a subreddit of Georgia Tech. Most of the most have sentiment so you rarely pick a neutral option, mostly it's either positive or negative. Sometimes, it's neutral mostly when it's a question. Answer only with a single digit: 1 for positive, -1 for negative, 0 for neutral\"},\n",
    "    {\"role\": \"user\", \"content\": positive_post}  \n",
    "  ]\n",
    ")\n",
    "print(positive_post)\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/c4l8s0b1199bp9tl5hlxr75w0000gn/T/ipykernel_88050/553132700.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  non_empty_selftext_df['4o-mini-sentiment-middle'] = non_empty_selftext_df['combined_text_middle'].apply(get_sentiment)\n"
     ]
    }
   ],
   "source": [
    "# let's run this evaluation on the middle part of the post for all entries\n",
    "non_empty_selftext_df['4o-mini-sentiment-middle'] = non_empty_selftext_df['combined_text_middle'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of same values: 1180\n",
      "Number of different values: 90\n"
     ]
    }
   ],
   "source": [
    "# let's compare how different the result is with the full-text analysis\n",
    "same_values_count = (non_empty_selftext_df['4o-mini-sentiment'] == non_empty_selftext_df['4o-mini-sentiment-middle']).sum()\n",
    "different_values_count = (non_empty_selftext_df['4o-mini-sentiment'] != non_empty_selftext_df['4o-mini-sentiment-middle']).sum()\n",
    "\n",
    "print(f\"Number of same values: {same_values_count}\")\n",
    "print(f\"Number of different values: {different_values_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, we can save the different posts for further analysis\n",
    "different_sentiment_df = non_empty_selftext_df[non_empty_selftext_df['4o-mini-sentiment'] != non_empty_selftext_df['4o-mini-sentiment-middle']]\n",
    "# different_sentiment_df.to_csv('different_sentiment_posts.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Here is a list of important people and things that did not exist the last time Georgia Tech Football entered a game with a winning record on December 26, 2018\n",
      "4o-mini-sentiment: 1\n",
      "4o-mini-sentiment-middle: 0\n",
      "Link: https://www.reddit.com/r/gatech/comments/y9akuf/here_is_a_list_of_important_people_and_things/\n",
      "\n",
      "Title: Why do free t shirt people not stock enough mediums?\n",
      "4o-mini-sentiment: -1\n",
      "4o-mini-sentiment-middle: 0\n",
      "Link: https://www.reddit.com/r/gatech/comments/u8stwx/why_do_free_t_shirt_people_not_stock_enough/\n",
      "\n",
      "Title: Fearful and Anxious for CS 1331 Summer 23 with Landry,advice and help would be appreciated\n",
      "4o-mini-sentiment: -1\n",
      "4o-mini-sentiment-middle: 0\n",
      "Link: https://www.reddit.com/r/gatech/comments/13hua77/fearful_and_anxious_for_cs_1331_summer_23_with/\n",
      "\n",
      "Title: I‘m trying to get in contact with undergrad admission, not ever getting through\n",
      "4o-mini-sentiment: 0\n",
      "4o-mini-sentiment-middle: -1\n",
      "Link: https://www.reddit.com/r/gatech/comments/yx685i/im_trying_to_get_in_contact_with_undergrad/\n",
      "\n",
      "Title: Georgia Tech Professor looking to give advice on Grad school application and interviews\n",
      "4o-mini-sentiment: 1\n",
      "4o-mini-sentiment-middle: 0\n",
      "Link: https://www.reddit.com/r/gatech/comments/s9ntcw/georgia_tech_professor_looking_to_give_advice_on/\n",
      "\n",
      "Title: If you get a scam email forward it to phishing@gatech.edu\n",
      "4o-mini-sentiment: 1\n",
      "4o-mini-sentiment-middle: 0\n",
      "Link: https://www.reddit.com/r/gatech/comments/w5n5kl/if_you_get_a_scam_email_forward_it_to/\n",
      "\n",
      "Title: Seeking Participants for Research Study Centered Around Visual Novels\n",
      "4o-mini-sentiment: 1\n",
      "4o-mini-sentiment-middle: 0\n",
      "Link: https://www.reddit.com/r/gatech/comments/y8ceew/seeking_participants_for_research_study_centered/\n",
      "\n",
      "Title: Petition to ask Brent Key to change his first name to “Interim Coach”\n",
      "4o-mini-sentiment: 1\n",
      "4o-mini-sentiment-middle: -1\n",
      "Link: https://www.reddit.com/r/gatech/comments/yzs94a/petition_to_ask_brent_key_to_change_his_first/\n",
      "\n",
      "Title: GT Aquarium Tickets Buy/Sell\n",
      "4o-mini-sentiment: 0\n",
      "4o-mini-sentiment-middle: 1\n",
      "Link: https://www.reddit.com/r/gatech/comments/113xz2r/gt_aquarium_tickets_buysell/\n",
      "\n",
      "Title: Six exposed to fentanyl inside suspicious package on Georgia Tech Campus (WSB)\n",
      "4o-mini-sentiment: 1\n",
      "4o-mini-sentiment-middle: -1\n",
      "Link: https://www.reddit.com/r/gatech/comments/143qr76/six_exposed_to_fentanyl_inside_suspicious_package/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's examine manually the post where 4o-mini had different sentiments for the full text and middle of the text\n",
    "random_20_posts = different_sentiment_df.sample(n=10, random_state=1)\n",
    "for index, row in random_20_posts.iterrows():\n",
    "    print(f\"Title: {row['title']}\")\n",
    "    print(f\"4o-mini-sentiment: {row['4o-mini-sentiment']}\")\n",
    "    print(f\"4o-mini-sentiment-middle: {row['4o-mini-sentiment-middle']}\")\n",
    "    print(f\"Link: {row['url']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sentiment results to a new (or the old) file\n",
    "non_empty_selftext_df = non_empty_selftext_df.drop_duplicates(subset='name')\n",
    "non_empty_selftext_df.to_csv('../data/reddit_posts_3_years.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit-sentiment-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
